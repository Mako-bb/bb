<h1 align="center">
  <img align="center"; src="https://s3.invisionapp-cdn.com/storage.invisionapp.com/boards/files/183060432.png?x-amz-meta-iv=1&x-amz-meta-ck=cd20ea812f8ae161523111afa5aea5e8&AWSAccessKeyId=AKIAWCDCF6QSLTS7LRWT&Expires=1630454400&Signature=KwA0MwTV%2FpNqzz72M50hjiTA3%2B4%3D"; width="40"; height="30">
    Agentes - Gu√≠a de inicio y buenas pr√°cticas
</h1>

## üòÑ Introducci√≥n
  En este espacio contamos lo m√°s breve posible, todo lo que debe saber un/a desarrollador/a que est√© trabajando dentro de este repositorio.

  En **BB** hay varios proyectos y desarrollos en constante crecimiento, pero solo las personas que trabajamos diariamente en este repositorio, somos parte de un equipo llamado **"Team Scraping"**. Es as√≠, una manera en la cual nos suelen identificar dentro de la empresa.

  El elegante y distinguido **Team Scraping** se organiza y se comunica de la siguiente manera:
  - Usamos metodolog√≠a **Scrum** y la herramienta [**ClickUp**](https://app.clickup.com/) para organizar nuestros proyectos. [**M√°s informaci√≥n haciendo click aqu√≠.**](#)
  - Usamos **Microsoft Teams**. Tenemos canales y chats para seguir los temas relacionados a nuestros proyectos y el trabajo diario. [**M√°s informaci√≥n haciendo click aqu√≠.**](#)
  - Usamos **Microsoft Sharepoint** para realizar posteos de novedades, cosas que queramos comunicar al equipo o el resto de la empresa. [**M√°s informaci√≥n haciendo click aqu√≠.**](https://businessbureau0.sharepoint.com/sites/IT2)
    
  **B√°sicamente, en este repositorio trabajamos teniendo en cuenta tres puntos importantes:**
  1) Scrapear contenidos de plataformas **"On Demand"** de todo el mundo.
  2) Analizar la metadata de estos contenidos que obtenemos.
  3) Finalizar y automatizar la carga de datos.

  ***Es decir, realizamos un proceso ETL (Extract, transform and load).***

  Para el **1er** punto, antes que nada, es necesario esta leer y entender esta **Gu√≠a de inicio y buenas pr√°cticas**.
  
  Para el **2do** punto, es necesario leer y entender la **Documentaci√≥n para analizar metadata**.

  Y por √∫ltimo, para el **3er** punto, es necesario leer y entender la secci√≥n **√öltimos detalles que debemos saber y mejora continua**.

  Estos **tres puntos importantes**, los explicamos paso a paso en el siguiente [**√çndice**](https://gitlab.com/dondeloveo-for-business/agentes#%C3%ADndice) que tenemos m√°s abajo leyendo este [README.md](https://gitlab.com/dondeloveo-for-business/agentes#agentes-gu%C3%ADa-de-inicio-y-buenas-pr%C3%A1cticas)

  Pero si sos nuevo recomendamos ver cada uno de los tutoriales que tenemos [**aqu√≠**](https://businessbureau0.sharepoint.com/sites/IT2/SitePages/Capacitaciones.aspx) para que estes super integrado al equipoü§©.

## üìñ √çndice

**1 - Gu√≠a de inicio y buenas pr√°cticas**

1) [Aclaraciones importantes](https://gitlab.com/dondeloveo-for-business/agentes#aclaraciones-importantes)
2) [Instalaci√≥n de nustro entorno de trabajo](https://gitlab.com/dondeloveo-for-business/agentes#instalaci√≥n-de-nustro-entorno-de-trabajo)
3) [Convenciones del equipo y buenas pr√°cticas](https://gitlab.com/dondeloveo-for-business/agentes#convenciones-del-equipo-y-buenas-pr√°cticas)
4) [Crear un nuevo script](https://gitlab.com/dondeloveo-for-business/agentes#crear-un-nuevo-script)
5) [C√≥mo documentar un script](https://gitlab.com/dondeloveo-for-business/agentes#c√≥mo-documentar-un-script)
6) [Otros comandos](https://gitlab.com/dondeloveo-for-business/agentes/-/tree/master#otros-comandos)
7) [Reset trial de apps](https://gitlab.com/dondeloveo-for-business/agentes#reset-trial-para-nosqlbooster-y-studio3t)
<br>

**2 - Documentaci√≥n para analizar metadata**

Aqu√≠ definimos las necesidades del negocio.
  1) [Scrapings](https://gitlab.com/dondeloveo-for-business/agentes/-/blob/master/docs/scrapings.md)
  2) [Revisi√≥n Metadata](https://gitlab.com/dondeloveo-for-business/agentes/-/blob/master/docs/revision_metadata.md)
  3) [Analisis de datos con Excel](https://gitlab.com/dondeloveo-for-business/agentes#analizar-datos-con-excel)
  4) [Analisis de datos con Pandas](https://gitlab.com/dondeloveo-for-business/agentes#analizar-datos-con-pandas)

**3 - √öltimos detalles que debemos saber y mejora continua**
  1) [Comandos y Procesos Titanlog](https://gitlab.com/dondeloveo-for-business/agentes/-/blob/master/docs/comandos.md)
  2) [C√≥mo solicitar VPN's](https://businessbureau0.sharepoint.com/sites/IT2/SitePages/VPN.aspx)
  2) [Gitflow - ¬øPor qu√© trabajamos sobre platforms-dev?](https://gitlab.com/dondeloveo-for-business/agentes/-/blob/master/docs/gitflow.md)
  3) [Ideas](https://app.clickup.com/3043480/docs/2ww4r-178/2ww4r-381)

## üë®‚Äç‚öñÔ∏è Aclaraciones importantes

El c√≥digo fuente de este repositorio es **propiedad de BB-Business Bureau** y est√° prohibida su difusi√≥n y/o utilizaci√≥n por intereses ajenos a la empresa.

Sabemos que muchos de nosotros somos desarrolladores, nerds, entusiastas, nos gusta el anim√© y **siempre vemos muchas cosas para mejorar**. Pero hoy _agentes_ creci√≥ un mont√≥n, y un m√≠nimo cambio por fuera de estos archivos en los cuales indicamos desarrollar nuestro c√≥digo, puede generar problemas en la operaci√≥n diaria.
Es por esto, que las ideas de mejora, las estamos volcando en este [**link**](https://app.clickup.com/3043480/docs/2ww4r-178/2ww4r-381), para luego planificarlas y matarializarlas.

## üë©‚Äçüíª Instalaci√≥n de nustro entorno de trabajo

1) Clonar el repositorio.

Recomendamos hacerlo en una carpeta dentro de nuestra computadora, en donde organicemos nuestros archivos de trabajo.
Para clonar solo la rama de desarrollo **platforms-dev** usamos el comando:

**Git clone https://gitlab.com/dondeloveo-for-business/agentes.git -b platforms-dev --single-branch**

2) Luego, nos ubicarnos dentro del repositorio con nuestra terminal predilecta y, a la altura donde est√° ubicado este mismo archivo, en la carpeta clonada llamda **agentes** creamos un entorno virtual.

Hay varios entornos virtuales, pero en este caso recomendamos el que ofrece la documentaci√≥n oficial de Python: https://docs.python.org/3/library/venv.html

Para crear el entorno virtual, ejecutamos el siguiente comando:

```shell
mi-nombre@pc123:~/Desktop/agentes$ python -m venv env
```
Luego accedemos al entorno virtual, lo corrobramos cuando vemos la terminal de esta manera:

```shell
(env) mi-nombre@pc123:~/Desktop/agentes$
```

3) Ahora ubicados dentro del entorno virtual, instalar las dependencias:

**Para desarrollo:**
```shell
(env) mi-nombre@pc123:~/Desktop/agentes$ pip install -r requirements/local.txt
```

**Importante:** Todas las librer√≠as locales deben ir en requirements/local.txt . En caso de necesitar nuevas librer√≠as en los servidores, comunicarse con los l√≠deres del equipo.

**Para producci√≥n:**
```shell
(env) mi-nombre@pc123:~/Desktop/agentes$ pip install -r requirements/production.txt
```

4) Hay que instalar MongoDB y crear una base de datos local que escuche en el **puerto 27017**. Tambien se puede instalar un contenedor de Docker con un volumen para resguardar los datos (Esto √∫ltimo recomendado para desarrolladores m√°s experimentados).

Link para instalar seg√∫n el sistema operativo: https://docs.mongodb.com/manual/installation/

5) Por √∫ltimo hay que instalar un cliente para consumir los datos de MongoDB en localhost. Recomendamos instalar Studio 3T, pero se puede utilizar el que el desarrollador considere.

Link para instalar seg√∫n el sistema operativo: https://studio3t.com/download/

## üë©‚Äçüè´ Convenciones del equipo y buenas pr√°cticas
**Idioma**
- Nombre de variables, m√©todos y clases en ingl√©s.
- Documentaci√≥n en castellano.
- Logs en castellano.

**Buenas pr√°cticas**
- Debemos seguir las buenas pr√°cticas para escribir c√≥digo de [PEP8](https://www.python.org/dev/peps/pep-0008/)
- Variables que hagan referencia a lo que son.
- C√≥digo modular, separar en m√©todos por partes.
- Que el c√≥digo lo entienda cualquiera.
- Documentaci√≥n eficaz. Que cualquiera pueda entender el c√≥digo.
- Utilizar el config.yaml y evitar escribir urls, tags, queries y otras cosas no mantenibles en el c√≥digo.
- Que los logs indiquen el progreso de scraping de la plataforma.
- Utilizamos los mejores principios y buenas pr√°cticas de programaci√≥n como DRY, KISS, YAGNI y SOLID.

**Commits**
- Se debe dejar un breve y expl√≠cito mensaje en el commit. Deben ser en ingl√©s. Se recomienda hacer un commit cada vez que se modifica un archivo, o si se modifican varios, hacer un resumen en el mensaje del commit.

  - Por ejemplo si cre√© el archivo pepito.py indicamos: **git commit -m "Create pepito.py**
  - Por ejemplo si modifiqu√© el archivo pepito.py indicamos: **git commit -m "Update pepito.py**
  - Por ejemplo si elimin√© el archivo pepito.py indicamos: **git commit -m "Delete pepito.py**

**Rama platforms-dev**

El equipo **solo puede trabajar en esta rama** y modificar **solo** los siguientes archivos:
- Archivos dentro de la **carpeta platforms-dev**
- config.yaml

**Rama master**
- Solo personas autorizadas pueden crear versiones en esta rama. El resto del equipo debe trabajar en la rama **platforms-dev**.

***IMPORTANTE:*** Cambios en cualquier otro archivo del repositorio no ser√°n aceptados sin autorizaci√≥n de los l√≠deres del equip√≥. Los nuevos features se organizan con l√≠deres. Se escuchan muchas propuestas, pero es necesario evaluar la necesidad y factibilidad de nuevo c√≥digo **(Principio YAGNI)**.

## üë®‚Äçüç≥ Crear un nuevo script

Nos toca scrapear una plataforma que se llama **Pepito**, entonces...

1) Indicamos en el archivo **config.yaml** los datos b√°sicos de la plataforma a la altura de **ott_sites**, por ejemplo:

```yaml
ott_site:
  Pepito:
    countries:
      US: us.pepito # Es el PlatformCode -> Es muy importante validar este PlatformCode con los l√≠deres del equipo.
    api_url: https://www.pepito.com/v3/api/
```

2) Crear un archivo nuevo en **agentes/platforms**. El nombre del archivo tiene que referir obviamente al sitio al cual vamos a scrapear. Por ejemplo: **pepito.py**.

**IMPORTANTE:** Si el nombre de la plataforma est√° compuesta **por m√°s de una palabra**, no usar **snake case** espaciando con **"_"** y unimos todo.
Por ejemplo:

La plataforma se llama **"Pepito America"**
- Nombre correcto para el archivo: **pepitoamerica.py**
- Nombre **incorrecto** para el archivo: **pepito_america.py**

3) **Es muy importante** que el nombre de la clase sea igual al nombre del archivo sin **.py** ni  y que est√© en **CamelCase**. Por ejemplo el nombre de la clase dentro del script **pepito.py** puede ser:

```python
class Pepito()
    pass
```

Ejemplo si la plataforma esta compuesta **por m√°s de una palabra**:
Si la plataforma se llama **"Pepito America"**
- Nombre **correcto** para la clase: 
```python
class PepitoAmerica()
    pass
```
- Nombres **incorrectos** para la clase:
  - **pepitoAmerica**
  - **Pepito_America**
  - **PEPITOAMERICA**

4) Ahora debemos escribir las siguientes l√≠neas de c√≥digo.

```python
# -*- coding: utf-8 -*-
import json
import time
import requests
from common import config
from updates.upload import Upload
from handle.replace import _replace
from handle.mongo import mongo
# Traer solo las librer√≠as necesarias.

class Pepito():
    """
    Pepito es una ott de Estados Unidos.
    """
    def __init__(self, ott_site_uid, ott_site_country, operation):
        self.config = config()['ott_sites'][ott_site_uid]
        self.created_at = time.strftime("%Y-%m-%d")
        self.titanScraping = config()['mongo']['collections']['scraping']
        self.titanScrapingEpisodes = config()['mongo']['collections']['episode']
        self.mongo = mongo()
        self.platform_code = self.config['countries'][ott_site_country].lower()        
        # Completar el constructor de la clase!!!

        if operation == 'return':
            params = {"PlatformCode" : self.platform_code}
            last_item = self.mongo.lastCretedAt(self.titanScraping, params)
            if last_item.count() > 0:
                for last_content in last_item:
                    self.created_at = last_content['CreatedAt']
            self._scraping()
        
        elif operation == 'scraping':
            self.scraping()

        elif operation == 'testing':
            self.scraping(testing=True)

    def scraping(self, testing=False):
        # Escribir el c√≥digo aqui!!!

        print("¬°Probando!")

        # Este objeto es importante para verificar la informaci√≥n que se almacene en
        # MongoDB local.
        Upload(self.platform_code, self.created_at, testing=testing)
```

Este script **pepito.py** se instancia en **main.py** con el nombre de su clase, pero
cambiada a **"lowercase"**.

5) Por √∫ltimo, para ejecutarlo, debemos realizar el siguiente comando:

```shell
(env) mi-nombre@pc123:~/Desktop/agentes$ python main.py Pepito --c US --o testing
```
Si luego de ejecutar vemos **¬°Probando!** en la terminal, ¬°Todo se instal√≥ correctamente!

## üë©‚Äçüîß C√≥mo documentar un script

El c√≥digo escrito en python en s√≠, ya es bastante legible, pero sin duda, documentar el c√≥digo nos ahorrar√° responder muchas preguntas a futuro.

El equipo documenta el script dentro de la clase de la siguiente manera:

```python
# -*- coding: utf-8 -*-
import json
import time
import requests
from handle.mongo import mongo

class Pepito():
    """
    Pepito es una ott de Estados Unidos.

    DATOS IMPORTANTES:
    - Versi√≥n Final: Si/No (En desarrollo).
    - VPN: Si/No (Recomendaci√≥n: Usar ExpressVPN).
    - ¬øUsa Selenium?: Si/No.
    - ¬øTiene API?: Si/No.
    - ¬øUsa BS4?: Si/No.
    - ¬øSe relaciona con scripts TP? Si/No. ¬øCuales?
    - ¬øInstanacia otro archivo de la carpeta "platforms"?: Si/No. ¬øCuales?
    - ¬øCuanto demor√≥ la ultima vez? tiempo + fecha.
    - ¬øCuanto contenidos trajo la ultima vez? cantidad + fecha.

    OTROS COMENTARIOS:
    Con esta plataforma pasa lo siguiente...
    """
    def __init__(self, ott_site_uid, ott_site_country, type):
        self._config = config()['ott_sites'][ott_site_uid]
        self._created_at = time.strftime("%Y-%m-%d")
        self.mongo = mongo()
```
Documentamos los m√©todos de la siguiente manera:
```python
    def get_payloads(self, pais, cod_idioma, datos_contenido):
        """Obtiene el payload del contenido. # Indicar que hace el m√©todo.

        Args:
            # Indicar argumentos y tipo de datos.
            pais (str): Indica el pa√≠s del contenido.
            cod_idioma (str): Indica el idioma del contenido.
            datos_contenido (dict): Diccionario con toda la informaci√≥n del contenido.

        Returns:
            # En caso de retornar algo, indicar qu√© retorna.
            list: Retorna el payload en una lista.
        """
        contenidos = []

        return contenidos
```

## üë®‚Äçüîß Otros comandos

Estos se utilizan en proyectos particulares adhoc.

* IMDb Match And Piracy Agents Update `python main.py Work --o adhoc --t allPiracy`
* IMDb Match Companies Only `python main.py Work --o adhoc --t PiracyM` 
* Scraping Piracy `python main.py Piracy --o piracy` 

## üë®‚Äçüíª Reset trial de apps

Hay un script presente en agentes que _resetea_ el trial de los siguientes programas:
* Studio3T
* NoSQLBooster
* Datagrip

Este script funciona tanto para Windows, Linux y Mac.


## Uso:
El comando ser√≠a el siguiente:
```bash
python resetdb.py --p <program>
```

Donde ___\<program\>___ debe ser cualquiera de las siguientes opciones. La opci√≥n ___all___ elije todos.
  - studio3t
  - s3t
  - nosqlbooster
  - nsb
  - datagrip
  - dg
  - all


Por ejemplo, para reiniciar Studio3T, escribir lo siguiente:
```bash
python resetdb.py --p s3t
```

### NOTAS:
  - _**IMPORTANTE**_: Esto borrar√° las conexiones y configuraciones creadas en todos los programas. Exportar las conexiones existentes desde cada app antes de ejecutar el camando previo.
  - En Windows puede que se tenga que ejecutar 2 veces el script(1 como usuario normal y otro como administrador) en el caso que se elija Studio3T porque tiene alojado datos en el __registro de Windows__ que est√°n disponibles en m√∫ltiples registros.
  - Con NoSQLBooster funciona temporalmente. Falta corregirlo.
  - El crack de Studio3T para Mac no funciona perfectamente en algunos casos. Falta corregirlo.
<br>

## üïµÔ∏è Analizar datos con Excel

Antes de terminar una plataforma, es importante revisar la metadata. Para exportar un excel que tenga hojas con las colecciones **titanScraping**, **titanScrapingEpisodes** (que estan en mi localhost de mongo) y **apiPresence** (que est√° en misato), puedo ejecutar los comandos que veremos a continuaci√≥n. Para ejecutar esto, es necesaro tener instalada la librer√≠a **pandas** en local.

Por ejemplo, si la plataforma se llama **Pepito** y el pa√≠s a analizar es **US**:

**Debo ejecutar en la terminal:** `python main.py Pepito --c US --o excel`

Ahora, si quiero traer una fecha en particular, por ejemplo, datos que tengo en mi localhost de mongo del 01/03/2020...

**Debo ejecutar en la terminal:** `python main.py Pepito --c US --o excel --date 2020-03-01`

Si no indico fecha, me trae datos del d√≠a. De **apiPresence** trae la √∫ltima actualizaci√≥n.

Una vez exportado el excel, puedo aplicar funciones, crear nuevas hojas, hacer tablas din√°micas, o cualquier cosa que se me ocurra para analizar y validar los datos de una plataforma. La extension **.xlsx** est√° ignorada en **.gitignore**.

**Por √∫ltimo**, Es importante que se agrege una hoja llamada **"an√°lisis"** y aqu√≠ dar un detalle de la metadata que trae un script.

[Click aqu√≠ para ver un mini tutorial de an√°lisis de datos con Excel](#)

## üïµÔ∏è Analizar datos con Pandas

**Importante:** Si nunca cre√© un notebook, explicamos c√≥mo instalar **Jupyter Notebook** haciendo click [aqu√≠](https://gitlab.com/dondeloveo-for-business/agentes#instalar-jupyter-notebook). 

Aqu√≠ explicamos c√≥mo crear **Dataframes** de mongo muy f√°cil, y analizarlos con **Jupyter**, **Jupyter Lab**, **Spyder** o con el *notebook/entorno* que m√°s me guste.

Recomendamos ejecutar el *notebook/entorno* favorito sobre la carpeta **analysis**, que est√° dentro de este repositorio **agentes**.

Para traer un **DataFrame** de **localhost > titan** ejecuto:
```python
from utils import GetDataFrame
query = {"PlatformCode":"us.pepito", "CreatedAt": "2020-03-01"}
df = GetDataFrame.local(query, collection='titanScraping')
df
```
Si quiero traer un **DataFrame** de **kaji > bussines**, debo usar el m√©todo **kaji**:
```python
df = GetDataFrame.kaji(query, collection='titanScraping')
```
Traer un Dataframe de **misato > bussines**, debo usar el m√©todo **misato**:
```python
df = GetDataFrame.misato(query, collection='apiPresence')
```
Donde **query** debe ser un diccionario, y el argumento **collection** debe ser una colecci√≥n de la base de datos de mongo.

Listo, ahora puedo analizar o comparar DataFrames. La extension **.ipynb** y las carpetas **.ipynb_checkpoints** est√°n ignoradas en **.gitignore**.

**Tip:** Puedo usar regex para hacer consultas, por ejemplo, mi **query** puede ser:

```python
query = {'PlatformCode' : { '$regex' : '.pepito', '$options' : 'i' } }
```

Al finalizar el an√°lisis, se puede importar a html con el comando: `jupyter nbconvert --to (formato)archivo.ipynb`

[Click aqu√≠ para ver un mini tutorial de an√°lisis de datos con Pandas](#)

## üêç Instalar Jupyter Notebook

Antes que nada, debemos tener el entorno virtual activado y posicionarnos sobre la carpeta analysis:

```shell
(env) mi-nombre@pc123:~/Desktop/agentes/analysis$
```

Es importante tener instaladas las librer√≠as **pandas** y **jupyter** en nuestro entorno virtual.

Ahora debo ejecutar **jupyter notebook** en la terminal:

```shell
(env) mi-nombre@pc123:~/Desktop/agentes/analysis$ jupyter notebook
```
Una vez levantado el servidor, debemos ingresamos al link que inicia con **http://localhost:8888/**.

Creamos un nuevo notebook:
<p>
  <img align="center"; src="https://www.programaenpython.com/wp-content/uploads/2019/03/jupyter_notebook_menu_new.png"; width="110"; height="120">
</p>

¬°Ya podemos trabajar!
<p>
  <img align="center"; src="https://www.programaenpython.com/wp-content/uploads/2019/03/jupyter_notebook_blank-1024x190.png"; width="800"; height="150">
</p>